{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fd64a93",
   "metadata": {},
   "source": [
    "Q1. **What are the key tasks that machine learning entails? What does data pre-processing imply ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf28be1",
   "metadata": {},
   "source": [
    "**Ans**: There are Five core tasks in the common ML workflow:\n",
    "\n",
    "- Get Data: The first step in the Machine Learning process is getting data.\n",
    "- Cleaning, Preparing & Manipulating Data: Real-world data often has unorganized, missing, or noisy elements.\n",
    "- Train Model: This step is where the magic happens!\n",
    "- Testing Model.\n",
    "- Improving model.\n",
    "\n",
    "**Data Pre-processing**\n",
    "\n",
    "- Data preprocessing involves transforming raw data to well-formed data sets so that data mining analytics can be applied.\n",
    "- Preprocessing involves both data validation and data imputation\n",
    "- The Goal of Data Validation is to assess whether the data in question is both complete and accurate.\n",
    "- The Goal of Data Imputation is to correct errors and input missing values, Either Manually or Automatically through business process automation (BPA) programming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4998c7c",
   "metadata": {},
   "source": [
    "Q2. **Describe quantitative and qualitative data in depth. Make a distinction between the two ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7b3f84",
   "metadata": {},
   "source": [
    "**Ans**: The Data Type Is Broadly Classified Into:\n",
    "\n",
    "- Quantitative\n",
    "- Qualitative\n",
    "\n",
    "**Quantitative Data Type**: This Type Of Data Type Consists Of Numerical Values. Anything Which Is Measured By Numbers. E.G., Profit, Quantity Sold, Height, Weight, Temperature, Etc. This Is Again Of Two Types\n",
    "\n",
    "1. **Discrete Data Type**: – The Numeric Data Which Have Discrete Values Or Whole Numbers. This Type Of Variable Value If Expressed In Decimal Format Will Have No Proper Meaning. Their Values Can Be Counted. E.G.: – No. Of Cars You Have, No. Of Marbles In Containers, Students In A Class, Etc.\n",
    "2. **Continuous Data Type**: – The Numerical Measures Which Can Take The Value Within A Certain Range. This Type Of Variable Value If Expressed In Decimal Format Has True Meaning. Their Values Can Not Be Counted But Measured. The Value Can Be Infinite E.G.: Height, Weight, Time, Area, Distance, Measurement Of Rainfall, Etc.\n",
    "\n",
    "**Qualitative Data Type**: These Are The Data Types That Cannot Be Expressed In Numbers. This Describes Categories Or Groups And Is Hence Known As The Categorical Data Type. This Can Be Divided Into:-\n",
    "\n",
    "1. **Structured Data**: This Type Of Data Is Either Number Or Words. This Can Take Numerical Values But Mathematical Operations Cannot Be Performed On It. This Type Of Data Is Expressed In Tabular Format. E.G.) Sunny=1, Cloudy=2, Windy=3 Or Binary Form Data Like 0 Or1, Good Or Bad, Etc.\n",
    "2. **Unstructured Data**: This Type Of Data Does Not Have The Proper Format And Therefore Known As Unstructured Data.This Comprises Textual Data, Sounds, Images, Videos, Etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f586fd6",
   "metadata": {},
   "source": [
    "Q3. **Create a basic data collection that includes some sample records. Have at least one attribute from each of the machine learning data types ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc053b97",
   "metadata": {},
   "source": [
    "**Ans**: The following is a basic data collection that includes some sample records.\n",
    "\n",
    "**Determine What Information You Want to Collect**: The first thing you need to do is choose what details you want to collect. You’ll need to decide what topics the information will cover, who you want to collect it from and how much data you need. Your goals — what you hope to accomplish using your data — will determine your answers to these questions. As an example, you may decide to collect data about which type of articles are most popular on your website among visitors who are between the ages of 18 and 34. You might also choose to gather information about the average age of all of the customers who bought a product from your company within the last month.\n",
    "\n",
    "**Set a Timeframe for Data Collection**: Next, you can start formulating your plan for how you’ll collect your data. In the early stages of your planning process, you should establish a timeframe for your data collection. You may want to gather some types of data continuously. When it comes to transactional data and website visitor data, for example, you may want to set up a method for tracking that data over the long term. If you’re tracking data for a specific campaign, however, you’ll track it over a defined period. In these instances, you’ll have a schedule for when you’ll start and end your data collection.\n",
    "\n",
    "- Determine Your Data Collection Method \n",
    "- Collect the Data\n",
    "- Analyze the Data and Implement Your Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccc95ed",
   "metadata": {},
   "source": [
    "Q4.**What are the various causes of machine learning data issues? What are the ramifications ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1429f2d",
   "metadata": {},
   "source": [
    "**Ans**: There are several causes of data issues in machine learning. Some common causes include:\n",
    "\n",
    "**Missing or incomplete data**: This can occur when some data points are missing or incomplete, which can affect the accuracy and reliability of the machine learning model.\n",
    "\n",
    "**Incorrect or inconsistent data**: This can occur when the data is incorrect or inconsistent, which can also affect the accuracy and reliability of the machine learning model.\n",
    "\n",
    "**Outliers**: Outliers are data points that are significantly different from the rest of the data. These can have a disproportionate effect on the machine learning model, causing it to perform poorly.\n",
    "\n",
    "**Noise**: Noise refers to random variations in the data that can make it difficult for the machine learning model to accurately learn and make predictions.\n",
    "\n",
    "**Imbalanced data**: This occurs when the data is not evenly distributed, with some classes being underrepresented. This can make it difficult for the machine learning model to accurately learn and make predictions for the underrepresented classes.\n",
    "\n",
    "**Correlated features**: When two or more features are highly correlated, they can provide redundant information and make it difficult for the machine learning model to accurately learn and make predictions.\n",
    "\n",
    "There are various approaches that can be used to address these data issues, such as data cleaning, data preprocessing, and feature engineering. It is important to carefully examine and address these issues before training a machine learning model to ensure that it is able to accurately learn and make reliable predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75790aca",
   "metadata": {},
   "source": [
    "Q5. **Demonstrate various approaches to categorical data exploration with appropriate examples ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7e67aa",
   "metadata": {},
   "source": [
    "**Ans**:\n",
    "\n",
    "There are several approaches that can be used to explore categorical data. Here are a few examples:\n",
    "\n",
    "**Frequency counts**: This approach involves counting the number of occurrences of each category in the data. For example, if we have a categorical variable \"fruit\" with categories \"apple\", \"banana\", and \"orange\", we can use frequency counts to determine the number of occurrences of each category in the data.\n",
    "\n",
    "**Bar plots**: A bar plot is a graphical representation of categorical data. Each category is represented by a bar, and the height of the bar indicates the frequency or percentage of occurrences of that category. For example, if we have a categorical variable \"color\" with categories \"red\", \"green\", and \"blue\", we can use a bar plot to visualize the distribution of these categories in the data.\n",
    "\n",
    "**Pie charts**: A pie chart is another graphical representation of categorical data. It shows the distribution of categories as a percentage of the whole. For example, if we have a categorical variable \"gender\" with categories \"male\" and \"female\", we can use a pie chart to visualize the proportion of males and females in the data.\n",
    "\n",
    "**Cross-tabulation**: Cross-tabulation (or contingency table) is a way to compare the distribution of two or more categorical variables. For example, if we have a categorical variable \"fruit\" with categories \"apple\", \"banana\", and \"orange\" and another categorical variable \"color\" with categories \"red\", \"green\", and \"blue\", we can use cross-tabulation to see how the categories of the two variables are related to each other.\n",
    "\n",
    "**Chi-squared test**: The chi-squared test is a statistical test that can be used to determine if there is a significant association between two categorical variables. For example, if we have a categorical variable \"fruit\" with categories \"apple\", \"banana\", and \"orange\" and another categorical variable \"taste\" with categories \"sweet\", \"sour\", and \"bitter\", we can use the chi-squared test to see if there is a significant association between the categories of these two variables.\n",
    "\n",
    "These are just a few examples of approaches that can be used to explore categorical data. There are many other techniques and tools available for this purpose, depending on the specific needs and goals of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32301e1e",
   "metadata": {},
   "source": [
    "Q6. **How would the learning activity be affected if certain variables have missing values? Having said that, what can be done about it ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c993f5f",
   "metadata": {},
   "source": [
    "Ans: Even in a Well-Designed & Controlled study, Missing data occurs in almost all research. Missing data can reduce the statistical power of a study and can produce biased estimates, leading to invalid conclusions.\n",
    "\n",
    "- Real-world data collection has its own set of problems, It is often very messy which includes missing data, presence of outliers, unstructured manner, etc.\n",
    "- Before looking for any insights from the data, we have to first perform preprocessing tasks which then only allow us to use that data for further observation and train our machine learning model.\n",
    "- Missing value in a dataset is a very common phenomenon in the reality.\n",
    "- Missing value correction is required to reduce bias and to produce powerful suitable models.\n",
    "- Most of the algorithms can’t handle missing data, thus you need to act in some way to simply not let your code crash. So, let’s begin with the methods to solve the problem.\n",
    "- Methods for dealing with missing values. The popular methods which are used by the machine learning community to handle the missing value for categorical variables in the dataset are as follows: Delete the observations: If there is a large number of observations in the dataset, where all the classes to be predicted are sufficiently represented in the training data, then try deleting the missing value observations, which would not bring significant change in your feed to your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473b5182",
   "metadata": {},
   "source": [
    "Q7. **Describe the various methods for dealing with missing data values in depth ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aeb1b5",
   "metadata": {},
   "source": [
    "There are several methods for dealing with missing data values:\n",
    "\n",
    "1. **Deletion methods**: Deletion methods involve removing observations with missing values from the dataset. There are several types of deletion methods:\n",
    "- Listwise deletion: This method removes an entire observation if any value is missing. It is the most restrictive method and can lead to a reduction in the sample size, which may affect the statistical power of the analysis.\n",
    "\n",
    "- Pairwise deletion: This method removes only those values that are missing, rather than the entire observation. It is less restrictive than listwise deletion and can be useful when there are only a few missing values in the dataset.\n",
    "\n",
    "- Single imputation: This method involves replacing the missing value with a substitute value. There are several methods for single imputation, including mean imputation (replacing the missing value with the mean of the variable), median imputation (replacing the missing value with the median of the variable), and mode imputation (replacing the missing value with the most frequent value). Single imputation can be useful when there are only a few missing values in the dataset.\n",
    "\n",
    "2. **Prediction methods**: Prediction methods involve using a machine learning algorithm to predict the missing values based on the available data. These methods can be more accurate than imputation methods, but they require more advanced knowledge and skill to implement.\n",
    "\n",
    "3. **Multiple imputation**: Multiple imputation involves imputing the missing values multiple times, using different imputation methods or models. This can help to reduce the bias introduced by single imputation methods and provide more accurate estimates of the missing values.\n",
    "\n",
    "It is important to carefully consider the pros and cons of each method and choose the most appropriate one based on the specific needs and goals of the analysis. It is also important to carefully validate the chosen method to ensure that it is effective in dealing with the missing data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc1a4c1",
   "metadata": {},
   "source": [
    "Q8. **What are the various data pre-processing techniques? Explain dimensionality reduction and function selection in a few words ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de8f902",
   "metadata": {},
   "source": [
    "Ans: The Various Data Pre-Processing Techniques are:\n",
    "\n",
    "1. **Data Cleaning**: The data can have many irrelevant and missing parts. To handle this part, data cleaning is done. It involves handling of missing data, noisy data etc.\n",
    "\n",
    " - `Missing Data`: This situation arises when some data is missing in the data. It can be handled in various ways. Some of them are:\n",
    " - `Ignore the tuples`: This approach is suitable only when the dataset we have is quite large and multiple values are missing within a tuple.\n",
    " - `Fill the Missing values`: There are various ways to do this task. You can choose to fill the missing values manually, by attribute mean or the most probable value.\n",
    "2. **Noisy Data**: Noisy data is a meaningless data that can’t be interpreted by machines.It can be generated due to faulty data collection, data entry errors etc. It can be handled in following ways :\n",
    "\n",
    " - `Binning Method`: This method works on sorted data in order to smooth it. The whole data is divided into segments of equal size and then various methods are performed to complete the task. Each segmented is handled separately. One can replace all data in a segment by its mean or boundary values can be used to complete the task.\n",
    " - `Regression`: Here data can be made smooth by fitting it to a regression function.The regression used may be linear (having one independent variable) or multiple (having multiple independent variables).\n",
    " - `Clustering`: This approach groups the similar data in a cluster. The outliers may be undetected or it will fall outside the clusters.\n",
    "3. **Data Reduction**: Since data mining is a technique that is used to handle huge amount of data. While working with huge volume of data, analysis became harder in such cases. In order to get rid of this, we uses data reduction technique. It aims to increase the storage efficiency and reduce data storage and analysis costs. The various steps to data reduction are:\n",
    "\n",
    " - `Data Cube Aggregation`: Aggregation operation is applied to data for the construction of the data cube.\n",
    " - `Attribute Subset Selection`: The highly relevant attributes should be used, rest all can be discarded. For performing attribute selection, one can use level of significance and p- value of the attribute.the attribute having p-value greater than significance level can be discarded.\n",
    " - `Numerosity Reduction`: This enable to store the model of data instead of whole data, for example: Regression Models.\n",
    "4. **Dimensionality Reduction**: This reduce the size of data by encoding mechanisms.It can be lossy or lossless. If after reconstruction from compressed data, original data can be retrieved, such reduction are called lossless reduction else it is called lossy reduction. The two effective methods of dimensionality reduction are:Wavelet transforms and PCA (Principal Component Analysis).\n",
    "Feature selection is simply selecting and excluding given features without changing them. Dimensionality reduction transforms features into a lower dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923f39d6",
   "metadata": {},
   "source": [
    "Q9. **Make brief notes on of the following ?**\n",
    "\n",
    "- What is the IQR? What criteria are used to assess it?\n",
    "- Describe the various components of a box plot in detail? When will the lower whisker surpass the upper whisker in length? How can box plots be used to identify outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0c175a",
   "metadata": {},
   "source": [
    "**Ans**: The following is the brief notes on the following topics:\n",
    "\n",
    "What is the IQR? What criteria are used to assess it?\n",
    "\n",
    "- `Q1` is the first quartile of the data, i.e., to say 25% of the data lies between minimum and Q1.\n",
    "- `Q3` is the third quartile of the data, i.e., to say 75% of the data lies between minimum and Q3.\n",
    "- The difference between Q3 and Q1 is called the Inter-Quartile Range or IQR.\n",
    "\n",
    "Describe the various components of a box plot in detail? When will the lower whisker surpass the upper whisker in length? How can box plots be used to identify outliers?\n",
    "\n",
    "- `minimum is the minimum value in the dataset`\n",
    "- `maximum is the maximum value in the dataset.`\n",
    "\n",
    "So the difference between the two tells us about the range of dataset.\n",
    "The median is the median (or centre point), also called second quartile, of the data (resulting from the fact that the data is ordered).\n",
    "Q1 is the first quartile of the data, i.e., to say 25% of the data lies between minimum and Q1.\n",
    "Q3 is the third quartile of the data, i.e., to say 75%\n",
    "When the data is left skewed, lower whisker will be longer than upper whisker.\n",
    "\n",
    "To detect the outliers this method is used, we define a new range, let’s call it decision range, and any data point lying outside this range is considered as outlier and is accordingly dealt with. The range is as given below:\n",
    "Lower Bound: (Q1 - 1.5 * IQR)Upper Bound: (Q3 + 1.5 * IQR)\n",
    "\n",
    "The difference between Q3 and Q1 is called the Inter-Quartile Range or IQR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f8a646",
   "metadata": {},
   "source": [
    "Q10. **Make brief notes on any two of the following ?**\n",
    "1. Data collected at regular intervals\n",
    "2. The gap between the quartiles\n",
    "3. Use a cross-tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aaa5bc",
   "metadata": {},
   "source": [
    "Ans: The following are the brief notes about:\n",
    "\n",
    "***Data collected at regular intervals***:\n",
    "\n",
    "- Interval data is one of the two types of discrete data.\n",
    "- An example of interval data is the data collected on a thermometer—its gradation or markings are equidistant.\n",
    "- Unlike ordinal data, interval data always take numerical values where the distance between two points on the scale is standardised and equal.\n",
    "\n",
    "***The gap between the quartiles***:\n",
    "\n",
    "- Q1 is the first quartile of the data, i.e., to say 25% of the data lies between minimum and Q1.\n",
    "- Q3 is the third quartile of the data, i.e., to say 75% of the data lies between minimum and Q3.\n",
    "- The difference between Q3 and Q1 is called the Inter-Quartile Range or IQR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c2433",
   "metadata": {},
   "source": [
    "Q11. **Make a comparison between ?**\n",
    "- Data with nominal and ordinal values\n",
    "- Histogram and box plot\n",
    "- The average and median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c4728d",
   "metadata": {},
   "source": [
    "1.1 **Nominal data**: Nominal data is a type of categorical data that does not have any inherent order or ranking between the categories. The categories are simply labels or names for different groups or types. For example, the categorical variable \"fruit\" with categories \"apple\", \"banana\", and \"orange\" is a nominal variable, as the categories do not have any inherent order or ranking.\n",
    "\n",
    "1.2. **Ordinal data**: Ordinal data is a type of categorical data that has an inherent order or ranking between the categories. The categories can be ranked or ordered in terms of magnitude, importance, or some other measure. For example, the categorical variable \"satisfaction\" with categories \"very satisfied\", \"satisfied\", \"neutral\", \"dissatisfied\", and \"very dissatisfied\" is an ordinal variable, as the categories are ranked in terms of satisfaction level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca6b0b2",
   "metadata": {},
   "source": [
    "**Difference between Histogram and box plot**\n",
    "\n",
    "***Shape of the plot***: A histogram is a bar plot that shows the frequency or density of the data on the y-axis and the values of the data on the x-axis. It is used to show the distribution of the data and identify patterns or trends. A box plot, on the other hand, is a graphical representation of the minimum, first quartile, median, third quartile, and maximum values of the data. It is used to show the distribution and dispersion of the data and identify outliers.\n",
    "\n",
    "***Data type:*** A histogram is typically used to visualize continuous data, while a box plot is used to visualize both continuous and categorical data.\n",
    "\n",
    "***Summary statistics***: A histogram does not show summary statistics such as the mean or standard deviation, while a box plot shows the median and interquartile range, which can provide useful information about the distribution and dispersion of the data.\n",
    "\n",
    "Overall, a histogram is a useful tool for visualizing the distribution of continuous data, while a box plot is a useful tool for visualizing the distribution and dispersion of both continuous and categorical data. Both can be useful for understanding the characteristics of a dataset and identifying patterns and trends.\n",
    "\n",
    "**The average and median:**\n",
    "\n",
    "The mean (informally, the “average“) is found by adding all of the numbers together and dividing by the number of items in the set: 10 + 10 + 20 + 40 + 70 / 5 = 30. The median is found by ordering the set from lowest to highest and finding the exact middle. The median is just the middle number: 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd5347",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
