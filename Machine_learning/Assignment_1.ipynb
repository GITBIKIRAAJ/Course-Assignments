{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f29db972",
   "metadata": {},
   "source": [
    "Q1. **What does one mean by the term &quot;machine learning&quot;?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b8cbbb",
   "metadata": {},
   "source": [
    "**Machine learning** is a type of artificial intelligence that allows a computer to learn and improve its performance on a specific task without being explicitly programmed. It involves training a model on a large dataset, and then using that trained model to make predictions or decisions without being explicitly told how to do so.\n",
    "\n",
    "In machine learning, a model is trained on a dataset and then tested on a separate, unseen dataset to evaluate its performance. The goal is to train a model that can generalize well to new, unseen data, rather than just memorizing the training data.\n",
    "\n",
    "There are many different types of machine learning algorithms, including `supervised learning`, `unsupervised learning`, and `reinforcement learning`. In supervised learning, the model is trained on labeled data, where the correct output is provided for each example in the training set. In unsupervised learning, the model is not given any labeled examples and must find patterns and relationships in the data on its own. In reinforcement learning, the model is trained to make decisions in a dynamic environment to maximize a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29913578",
   "metadata": {},
   "source": [
    "Q2. **Can you think of 4 distinct types of issues where it shines ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da08b78",
   "metadata": {},
   "source": [
    "The following are some of the issues where Machine Learning can be used:\n",
    "\n",
    "**Image Recognition**: Image recognition is one of the most common applications of machine learning. It is used to identify objects, persons, places, digital images, etc. The popular use case of image recognition and face detection is Automatic friend tagging suggestion.\n",
    "\n",
    "**Speech Recognition**: While using Google, we get an option of Search by voice, it comes under speech recognition, and it's a popular application of Machine Learning. Speech recognition is a process of converting voice instructions into text, and it is also known as Speech to text, or Computer based speech recognition At present, machine learning algorithms are widely used by various applications of speech recognition. Google assistant, Siri, Cortana, and Alexa are using speech recognition technology to follow the voice instructions.\n",
    "\n",
    "**Traffic prediction**: It predicts the traffic conditions such as whether traffic is cleared, slow-moving, or heavily congested with the help of two ways: Real Time location of the vehicle form Google Map app and sensors Average time has taken on past days at the same time.\n",
    "\n",
    "**Product recommendations**: Machine learning is widely used by various e-commerce and entertainment companies such as Amazon, Netflix, etc., for product recommendation to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c150ff6",
   "metadata": {},
   "source": [
    "Q3. **What is a labeled training set, and how does it work ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7d2452",
   "metadata": {},
   "source": [
    "**Ans**:\n",
    "A **labeled training** set in machine learning is a collection of data that is used to train a model. Each example in the training set is a tuple consisting of an input and an output, where the input is a set of features that describe the example and the output is the correct label or class for that example.\n",
    "\n",
    "For example, if the task is to build a model that can classify images as either containing a dog or a cat, the training set would consist of a collection of images, each labeled as either `\"dog\" or \"cat\"`. The model would then be trained on this labeled training set by using the input images and the corresponding labels to learn the patterns and features that distinguish dogs from cats.\n",
    "\n",
    "During training, the model makes predictions based on the input features and is then updated based on the difference between the predicted output and the true label. This process is repeated multiple times until the model reaches a satisfactory level of `accuracy` on the training set.\n",
    "\n",
    "Once the model has been trained on the labeled training set, it can then be tested on a separate, unseen dataset to evaluate its performance. This dataset, called the test set, also consists of a collection of labeled examples that the model has not seen before. By comparing the model's predictions on the test set to the true labels, we can gauge how well the model generalizes to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a7fc83",
   "metadata": {},
   "source": [
    "Q4. **What are the two most important tasks that are supervised ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a70c07",
   "metadata": {},
   "source": [
    "**Ans**: The two most common supervised learning tasks are **`Regression`** and **`Classification`**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d03cb23",
   "metadata": {},
   "source": [
    "Q5. **Can you think of four examples of unsupervised tasks ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b9888e",
   "metadata": {},
   "source": [
    "**Clustering**: In clustering, the goal is to divide a dataset into groups or clusters based on some measure of similarity. For example, clustering algorithms might be used to group customers based on their purchase history, or to group text documents based on the words they contain.\n",
    "\n",
    "**Anomaly detection**: Anomaly detection algorithms are used to identify unusual or outlier data points in a dataset. For example, an anomaly detection model might be used to detect fraudulent credit card transactions or to identify malfunctioning equipment in a manufacturing plant.\n",
    "\n",
    "**Dimensionality reduction**: Dimensionality reduction algorithms are used to transform a dataset with a large number of features into a lower-dimensional space while preserving as much of the information in the original data as possible. This can be useful for visualization and for reducing the complexity of a model.\n",
    "\n",
    "**Generative modeling**: Generative models are used to learn the underlying structure of a dataset and generate new examples that are similar to the ones in the training set. For example, a generative model might be used to generate synthetic images or text that are similar to the examples in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723c058",
   "metadata": {},
   "source": [
    "Q6. **State the machine learning model that would be best to make a robot walk through various unfamiliar terrains ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0c2730",
   "metadata": {},
   "source": [
    "**Ans**:\n",
    "\n",
    "**Reinforcement learning** is a type of machine learning that involves training a model to make decisions in a dynamic environment in order to maximize a reward. In the case of a robot navigating unfamiliar terrains, the model could be trained to choose actions (e.g., move forward, turn left, turn right) that maximize the reward of successfully navigating the terrain.\n",
    "\n",
    "To train the model, the robot would need to be able to sense its environment and receive feedback in the form of a reward signal. For example, the reward signal could be positive for successfully navigating a terrain, and negative for falling or colliding with an obstacle. The model would then use this feedback to learn which actions are most likely to lead to successful navigation.\n",
    "\n",
    "Once the model has been trained, it can then be used to control the robot's movements and make decisions about which actions to take in order to navigate the terrain effectively. This approach allows the robot to learn and adapt to new environments without being explicitly programmed for each specific situation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee3dc49",
   "metadata": {},
   "source": [
    "Q7. **Which algorithm will you use to divide your customers into different groups ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8570ef53",
   "metadata": {},
   "source": [
    "**Ans**: The Best Algorithm to Segment Customers into different groups is either **Supervised Learning** (if the groups have known labels) or **Unsupervised Learning** (if there are no group labels)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7c2c8e",
   "metadata": {},
   "source": [
    "Q8. **Will you consider the problem of spam detection to be a supervised or unsupervised learning problem ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a1dace",
   "metadata": {},
   "source": [
    "Yes, Spam detection is a Supervised Machine Learning problem because the labels are known (`spam` or `no spam`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942b9730",
   "metadata": {},
   "source": [
    "Q9. **What is the concept of an online learning system ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb968697",
   "metadata": {},
   "source": [
    "**Ans**:\n",
    "**Online learning** is a type of machine learning where the model is trained on a dataset that is streamed to the model in a continuous fashion, rather than being presented all at once. The model is trained on one example at a time and updates its parameters based on each new example as it is received.\n",
    "\n",
    "Online learning systems are well-suited to situations where the dataset is too large to fit in memory or where the data is constantly changing, such as in a real-time streaming application. Because the model is continually being updated as new examples are received, it can adapt to changes in the data and improve its performance over time.\n",
    "\n",
    "One key characteristic of online learning systems is that they are able to learn incrementally, rather than needing to be retrained on the entire dataset every time there is a change. This makes them more efficient and allows them to learn from data in a more natural and dynamic way.\n",
    "\n",
    "However, online learning systems also have some challenges, such as the need to balance the trade-off between adapting to new data and preserving the information learned from previous examples. They may also be more sensitive to noisy or biased data, as each new example has the potential to significantly impact the model's parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cb6a8b",
   "metadata": {},
   "source": [
    "Q10. **What is out-of-core learning, and how does it differ from core learning ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6239fce",
   "metadata": {},
   "source": [
    "**Ans**:\n",
    "\n",
    "Out-of-core learning (also known as \"out-of-memory\" learning) is a type of machine learning that allows a model to be trained on a dataset that is too large to fit in the memory of a single machine. It involves breaking the dataset into smaller chunks, and training the model on each chunk one at a time.\n",
    "\n",
    "Out-of-core learning differs from \"in-core\" or \"in-memory\" learning, where the entire dataset is loaded into memory and processed all at once. In-core learning is typically more efficient, as it allows the model to make use of the full dataset and take advantage of fast access to the data in memory. However, it is not feasible when the dataset is too large to fit in memory.\n",
    "\n",
    "Out-of-core learning can be used to train models on very large datasets that would not be possible to process using in-core learning. However, it can be slower and more computationally intensive, as the model must be trained on each chunk of the dataset separately and then the results must be aggregated.\n",
    "\n",
    "Overall, the choice between in-core and out-of-core learning will depend on the size and nature of the dataset, as well as the available resources and the specific goals of the machine learning project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab6ab15",
   "metadata": {},
   "source": [
    "Q11. **What kind of learning algorithm makes predictions using a similarity measure ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232acbdc",
   "metadata": {},
   "source": [
    "**Ans**:\n",
    "**Learning algorithm** that relies on a similarity measure to make predictions is Instance Based Algorithm. The Machine Learning systems which are categorized as instance-based learning are the systems that learn the training examples by heart and then generalizes to new instances based on some similarity measure. It is called instance-based because it builds the hypotheses from the training instances. It is also known as memory-based learning or lazy-learning. The time complexity of this algorithm depends upon the size of training data. The worst-case time complexity of this algorithm is O (n), where n is the number of training instances.\n",
    "\n",
    "For example, If we were to create a spam filter with an instance-based learning algorithm, instead of just flagging emails that are already marked as spam emails, our spam filter would be programmed to also flag emails that are very similar to them. This requires a measure of resemblance between two emails. A similarity measure between two emails could be the same sender or the repetitive use of the same keywords or something else."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d88fde3",
   "metadata": {},
   "source": [
    "Q12. **What's the difference between a model parameter and a hyperparameter in a learning algorithm ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49878ac7",
   "metadata": {},
   "source": [
    "**Ans**:\n",
    "In a machine learning algorithm, a model ***parameter*** is a configuration value that is internal to the model and is learned from data during training. For example, in a linear regression model, the model parameters are the coefficients for each feature that are learned from the training data.\n",
    "\n",
    "On the other hand, a ***hyperparameter*** is a configuration value that is external to the model and is set by the practitioner before training. Hyperparameters are used to control the behavior of the learning algorithm and can have a significant impact on the model's performance.\n",
    "\n",
    "For example, in a neural network, some common hyperparameters include the learning rate, the number of hidden units, and the regularization coefficient. These hyperparameters are not learned from the data and must be set by the practitioner based on their understanding of the problem and the dataset.\n",
    "\n",
    "Tuning the hyperparameters of a learning algorithm is an important step in the machine learning process, as it can have a significant impact on the model's performance. In general, finding the optimal hyperparameter values requires experimentation and can involve techniques such as grid search or random search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7aed8e",
   "metadata": {},
   "source": [
    "Q13. **What are the criteria that model-based learning algorithms look for? What is the most popular method they use to achieve success? What method do they use to make predictions ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ecd2e9",
   "metadata": {},
   "source": [
    "**Ans**: ***Model based learning algorithm*** search for the optimal value of parameters in a model that will give the best results for the new instances. We often use a cost function or similar to determine what the parameter value has to be in order to minimize the function. The model makes prediction by using the value of the new instance and the parameters in its function. The goal for a model-based algorithm is to be able to generalize to new examples. To do this, model based algorithms search for optimal values for the model's parameters, often called theta. \n",
    "\n",
    "This searching, or \"learning\", is what machine learning is all about. Model-based system learn by minimizing a cost function that measures how bad the system is at making predicitons on new data, plus a penalty for model complexity if the model is regularized. To make a prediction, a new instance's features are fed into a hypothesis function which uses the minimized theta found by repeatedly running the cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee9cfb4",
   "metadata": {},
   "source": [
    "Q14. **Can you name four of the most important Machine Learning challenges ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bd6b2d",
   "metadata": {},
   "source": [
    "**Ans**: \n",
    "There are many challenges in the field of machine learning, but here are four that are considered particularly important:\n",
    "\n",
    "**Overfitting**: Overfitting occurs when a model is too complex for the underlying data and ends up fitting the noise or random variation in the data rather than the true underlying relationship. This can lead to poor generalization to new, unseen data.\n",
    "\n",
    "**Underfitting**: Underfitting occurs when a model is too simple and is unable to capture the complexity of the data. This can result in poor performance on the training data and poor generalization to new data.\n",
    "\n",
    "**Data quality**: The quality and relevance of the data used to train a machine learning model can have a significant impact on its performance. Poor-quality data, such as data that is biased or contains errors, can lead to inaccurate or misleading results.\n",
    "\n",
    "**Feature engineering**: Feature engineering is the process of selecting and designing the input features that will be used to train a machine learning model. This can be a challenging task, as it requires understanding the relationships between the features and the target variable, and selecting the most relevant and informative features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e58181",
   "metadata": {},
   "source": [
    "Q15. **What happens if the model performs well on the training data but fails to generalize the results to new situations? Can you think of three different options ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514d78a0",
   "metadata": {},
   "source": [
    "**Ans**: If a machine learning model performs well on the training data but fails to generalize the results to new situations, it is said to be overfitting. This means that the model has learned patterns and features that are specific to the training data and is not able to generalize to new, unseen examples.\n",
    "\n",
    "There are several strategies that can be used to address overfitting:\n",
    "\n",
    "**Collect more data**: One potential solution to overfitting is to collect more data to train the model on. This can help the model learn more general patterns and features rather than just memorizing the training data.\n",
    "\n",
    "**Use regularization**: Regularization is a technique that adds constraints to the model in order to prevent it from becoming too complex. This can help reduce overfitting by encouraging the model to learn more general patterns.\n",
    "\n",
    "**Use a simpler model**: Another approach to addressing overfitting is to use a simpler model with fewer parameters. This can help the model generalize better to new data, as it will be less prone to fitting the noise or random variation in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb253bad",
   "metadata": {},
   "source": [
    "Q16. **What exactly is a test set, and why would you need one ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ad82e2",
   "metadata": {},
   "source": [
    "**Ans**:A ***test set*** is a dataset that is used to evaluate the performance of a machine learning model. It is separate from the training set, which is used to train the model, and the validation set, which is used to fine-tune the model's hyperparameters.\n",
    "\n",
    "The purpose of the test set is to provide an unbiased evaluation of the model's performance on new, unseen data. It is important to use a test set because the model's performance on the training data is not a good indicator of its performance on new data.\n",
    "\n",
    "For example, if a model is trained on a dataset and then tested on the same dataset, it is likely to achieve very high accuracy because it has already seen all of the examples in the dataset. However, this does not necessarily mean that the model will perform well on new, unseen examples.\n",
    "\n",
    "Using a test set allows us to get a more realistic estimate of the model's performance on new data and helps us to identify any potential issues with the model's generalization ability.\n",
    "\n",
    "In general, it is good practice to set aside a portion of the dataset as a test set before starting the model training process. This allows us to evaluate the model's performance on new data and ensure that it is not overfitting to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf0ff7b",
   "metadata": {},
   "source": [
    "Q17. **What is a validation set's purpose ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b344ffb",
   "metadata": {},
   "source": [
    "**Ans**:\n",
    "\n",
    "Validation set is a set used to compare between different training models. Let's say we have a linear model and we want to perform some hyperparameter tuning to reduce the generalization error. One way to do this 100 different models with 100 different hyperparameter values using the training set and finding the generalization error with the test set. You find the best hyperparameter value gives you 5% generalization error.\n",
    "\n",
    "So you launch the model into production and find you're seeing 15% generalization error. This isn't going as expected. What happened?\n",
    "\n",
    "The problem is that for each iteration of hyperparameter tuning, you measured the generalization error then updated the model using the same test set. In other words, your produced the best generalization error for the test set. The test set no longer represents cases the model hasn't seen before.\n",
    "\n",
    "A common solution to this problem is to have a second holdout set called the validation set. You train multiple models with various hyperparameters using the training set, you select the model and hyperparameters that perform best on the validation set, and when you are happy about your model you run a single final test against the test set to get an estimate of the generalization error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6c42a6",
   "metadata": {},
   "source": [
    "Q18. **What precisely is the train-dev kit, when will you need it, how do you put it to use ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121441d6",
   "metadata": {},
   "source": [
    "Cross-validation is a tool to compare models without needing a separate validation set. It is preferred over validation set because we can save from breaking of part of the training set to create a validation set, as having more data is valuable regardless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90313a0",
   "metadata": {},
   "source": [
    "Q19. **What could go wrong if you use the test set to tune hyperparameters ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d300c7",
   "metadata": {},
   "source": [
    "**Ans**:  If you tune hyperparameters using the test sets, then it may not perform well on the out-of-sample data because the model is tuned just for that specific set. Our model will not be generalizable to new examples."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
